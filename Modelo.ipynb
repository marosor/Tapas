{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías básicas\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Librerías Machine Learning \n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet,LogisticRegression\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Librerías Model Selection y evaluación\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "# Librerías features transformación \n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   nacimiento  genero bebida_favorita  tapa_favorita  comunidad_autonoma\n",
      "0         NaN     NaN     Vino blanco            NaN                 NaN\n",
      "1         NaN     NaN      Vino tinto            NaN                 NaN\n"
     ]
    }
   ],
   "source": [
    "# Leer dataset \n",
    "\n",
    "ruta_archivo = 'data/tapas.xlsx'\n",
    "\n",
    "# Lee el archivo de Excel\n",
    "df = pd.read_excel(ruta_archivo)\n",
    "\n",
    "# Muestra las primeras filas del DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "train_set, test_set = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target\n",
    "target = 'tapa_favorita'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "columnas_categoricas = ['nacimiento','genero','bebida_favorita','comunidad_autonoma']\n",
    "features = columnas_categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   nacimiento  genero  bebida_favorita  tapa_favorita  comunidad_autonoma\n",
      "0           0       0                0            NaN                   0\n",
      "   nacimiento  genero  bebida_favorita  tapa_favorita  comunidad_autonoma\n",
      "1           0       0                1            NaN                   0\n"
     ]
    }
   ],
   "source": [
    "# Aplicar LabelEncoder a features\n",
    "train_set_encoded = train_set.copy()\n",
    "test_set_encoded = test_set.copy()\n",
    "for feature in features:\n",
    "    all_values = pd.concat([train_set[feature], test_set[feature]], axis=0).unique()\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(all_values)\n",
    "    train_set_encoded[feature] = label_encoder.transform(train_set[feature])\n",
    "    test_set_encoded[feature] = label_encoder.transform(test_set[feature])\n",
    "\n",
    "# Mostrar los DataFrames codificados\n",
    "print(train_set_encoded.head())\n",
    "print(test_set_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x y train/test\n",
    "X_train = train_set_encoded.drop(columns=['tapa_favorita'])\n",
    "y_train = train_set_encoded['tapa_favorita']\n",
    "X_test = test_set_encoded.drop(columns=['tapa_favorita'])\n",
    "y_test = test_set_encoded['tapa_favorita']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los modelos\n",
    "modelos = {\n",
    "    \"LightGBM\": LGBMRegressor(random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    \"Decision Tree Regressor\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Elastic Net\": ElasticNet(random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "}\n",
    "\n",
    "# Definir los hiperparámetros para cada modelo\n",
    "parametros = {\n",
    "    \"LightGBM\": {\n",
    "        'max_depth': [10, 20],\n",
    "        'n_estimators': [100, 200]\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        'max_depth': [10, 20],\n",
    "        'n_estimators': [100, 200]\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        'max_depth': [10, 20],\n",
    "        'n_estimators': [100, 200]\n",
    "    },\n",
    "    \"Linear Regression\": {\n",
    "        'fit_intercept': [True, False]\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        'max_depth': [10, 20],\n",
    "        'n_estimators': [100, 200]\n",
    "    },\n",
    "    \"Decision Tree Regressor\": {\n",
    "        'max_depth': [10, 20],\n",
    "        'min_samples_split': [2, 10]\n",
    "    },\n",
    "    \"Elastic Net\": {\n",
    "        'alpha': [0.1, 1.0, 10.0],\n",
    "        'l1_ratio': [0.1, 0.5, 0.9]\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        'n_neighbors': [3, 5, 7]\n",
    "    },\n",
    "    \"Decision Tree Classifier\": {\n",
    "        'max_depth': [10, 20],\n",
    "        'min_samples_split': [2, 10]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar validación cruzada y calcular balanced_accuracy\n",
    "for tipo, modelo in modelos.items():\n",
    "    print(f\"{tipo}: \", end=\" \")\n",
    "    scores = cross_val_score(modelo, X_train, y_train, cv=5, scoring=\"balanced_accuracy\")\n",
    "    print(np.mean(scores).round(2))\n",
    "print(\"******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo: LightGBM\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot have number of splits n_splits=3 greater than the number of samples: n_samples=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntrenando modelo: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnombre_modelo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodelo, param_grid\u001b[38;5;241m=\u001b[39mparametros[nombre_modelo], cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMejores parámetros para \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnombre_modelo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMejor score para \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnombre_modelo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search\u001b[38;5;241m.\u001b[39mbest_score_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mfm-8\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mfm-8\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:968\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    962\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    963\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    964\u001b[0m     )\n\u001b[0;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 968\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    972\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\mfm-8\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1543\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1542\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1543\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mfm-8\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:926\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    909\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    910\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    911\u001b[0m         )\n\u001b[0;32m    912\u001b[0m     )\n\u001b[0;32m    914\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    915\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    916\u001b[0m         clone(base_estimator),\n\u001b[0;32m    917\u001b[0m         X,\n\u001b[0;32m    918\u001b[0m         y,\n\u001b[0;32m    919\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    920\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    921\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    922\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    923\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    924\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    925\u001b[0m     )\n\u001b[1;32m--> 926\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m \u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    930\u001b[0m )\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    934\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    935\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mfm-8\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:409\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    407\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n\u001b[1;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    410\u001b[0m         (\n\u001b[0;32m    411\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits, n_samples)\n\u001b[0;32m    414\u001b[0m     )\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups):\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot have number of splits n_splits=3 greater than the number of samples: n_samples=1."
     ]
    }
   ],
   "source": [
    "# Grid Search\n",
    "resultados = {}\n",
    "for nombre_modelo, modelo in modelos.items():\n",
    "    print(f\"Entrenando modelo: {nombre_modelo}\")\n",
    "    grid_search = GridSearchCV(estimator=modelo, param_grid=parametros[nombre_modelo], cv=3, n_jobs=-1, scoring='r2')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f\"Mejores parámetros para {nombre_modelo}: {grid_search.best_params_}\")\n",
    "    print(f\"Mejor score para {nombre_modelo}: {grid_search.best_score_}\")\n",
    "    resultados[nombre_modelo] = grid_search.best_estimator_\n",
    "\n",
    "# Imprimir los mejores modelos y sus parámetros\n",
    "for nombre_modelo, mejor_modelo in resultados.items():\n",
    "    print(f\"Mejor modelo para {nombre_modelo}: {mejor_modelo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección manual del modelo (De momento por poner uno Random Forest)\n",
    "modelo_seleccionado = RandomForestRegressor(max_iter=1000, random_state=42)\n",
    "\n",
    "# Ajustar el modelo a los datos de entrenamiento\n",
    "modelo_seleccionado.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = modelo_seleccionado.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Métricas de evaluación\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, \u001b[43my_pred\u001b[49m)\n\u001b[0;32m      3\u001b[0m precision \u001b[38;5;241m=\u001b[39m precision_score(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall_score(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "# Métricas de evaluación\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "# Matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el directorio y la ruta del archivo\n",
    "models_dir = 'models'\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "results_file_path = os.path.join(models_dir, 'modelo.pkl')\n",
    "\n",
    "# Guardar el modelo en un archivo\n",
    "with open(results_file_path, 'wb') as file:\n",
    "    pickle.dump(modelo_seleccionado, file)\n",
    "\n",
    "print(f\"Modelo guardado en {results_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
